
Rag agent execution result is :
上周，我在美国国会大厦就人工智能和监管问题发表了演讲，此次活动吸引了立法界和企业界的领袖。我对开源社区在抵御可能扼杀创新的监管方面取得的进展感到鼓舞。然而，开源的反对者仍在不断变换他们的论点，最新的担忧集中在开源对国家安全的影响上。我们应继续共同保护开源环境！

根据我与立法者的对话，我对美国联邦政府在准确评估人工智能风险方面取得的进展感到鼓舞。明确地说，需要设置防护措施。但这些措施应针对人工智能的具体应用，而非通用人工智能技术本身。愿我们共同守护开源精神！尽管如此，正如我之前所写，一些公司急于限制开源，可能是为了保护他们在专有模型上所做的巨额投资价值，并阻止竞争对手。观察他们的论点随时间演变的过程一直颇具趣味。

例如，大约12个月前，人工智能安全中心发布的《人工智能风险声明》警告说，人工智能可能导致人类灭绝，并引发了人们对人工智能主导的担忧。这引起了华盛顿领导人的警觉。但许多人工智能领域的专家指出，这种反乌托邦科幻情景在现实中缺乏依据。大约六个月后，当我在美国参议院的人工智能洞察论坛上作证时，立法者们对人工智能接管的担忧已显著减少。然后，开源的反对者们转变了策略。他们主要的论点转变为人工智能可能帮助制造生物武器的风险。不久之后，OpenAI和RAND表明，当前的人工智能并没有显著增加恶意行为者制造生物武器的能力。这种关于人工智能辅助生物武器的担忧已有所减少。可以肯定的是，不良行为者可能使用生物武器——无论是否借助人工智能——仍然是国际上高度关注的话题。最新反对开放源代码AI的论点已转向国家安全问题。AI在经济竞争和战争中都有其用途，反对者认为美国应确保其对手无法接触到最新的基础模型。虽然我不希望专制政府使用AI，尤其是用于发动不公正的战争，但大语言模型的秘密已经泄露，如果民主国家限制访问，专制国家将会填补这一空白。当某天，某个地方的孩子向AI系统提问关于民主、自由媒体的角色或独立司法在维护法治中的作用时，我希望AI能体现民主价值观，而不是优先服务于专制领导者的目标，比如牺牲人权。离开华盛顿后，我对我们取得的进展感到乐观。一年前，立法者似乎将80%的时间用于讨论AI的监管框架，而仅20%的时间用于讨论投资创新。我很高兴这一比例已经逆转，现在更多地聚焦于投资创新。

除了美国联邦政府，全球还有许多法律辖区。不幸的是，支持那些可能阻碍AI发展的监管规定的论点仍在不断增加。但我从访问华盛顿和其他国家的首都的经历中学到，与监管机构的对话确实会产生影响。如果你有机会与任何级别的监管机构交流，我希望你能尽力协助政府更深入地理解AI。